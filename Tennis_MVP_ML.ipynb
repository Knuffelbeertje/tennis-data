{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Minimum Viable Product for Tennis Matches Results' Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the file of the preprocessing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "Tennis_MVP_df = pd.read_csv('Tennis_MVP.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to separate the explained variable from the predictors."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "y = Tennis_MVP_df['P1_WINS']\n",
    "x = Tennis_MVP_df\n",
    "x.drop('P1_WINS', axis = 1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adapt features set to Logistic Regression\n",
    "\n",
    "To be able to use Logistic Regression, we need to transform our **categorical** variables into **integer** ones. Specifically the surface variable and the names of the players.\n",
    "We can drop their names and the dates of the matcehs for the MVP as no \"memory\" features is present, it will be implemented at a later stage. <br>\n",
    "As for the surface, it is not an ordinal feature and we therefore have several options available such as One hot encoding or Label Binarizer. We can then use the *dummy* variables in our LR.\n",
    "We will also drop the tournaments' names for now."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "Tennis_MVP_df.drop(['P1_NAME','P2_NAME','T_NAME','T_DATE'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### OnehotEncoding - LabelBinarizer - get_dummies\n",
    "\n",
    "Need to look into the differences between these functions that allow to transform from categorical features to numerical ones.\n",
    "\n",
    "Online, they seem to indicate that get dummies is the easiest one to use as it links the news binary columns of each dummies to the names of their initial features.\n",
    "\n",
    "__[Link for reference](https://stackabuse.com/one-hot-encoding-in-python-with-pandas-and-scikit-learn/)__\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "surface_ohe = pd.get_dummies(Tennis_MVP_df.SURFACE, prefix='SURFACE')\n",
    "Tennis_MVP_df['SURFACE'] = surface_ohe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Data - Test Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.20, random_state=26)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "log_reg = LogisticRegression(random_state= 26)\n",
    "log_reg.fit(x_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=26)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "predictions = log_reg.predict(x_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "score = log_reg.score(x_test, y_test)\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "d69f459d14f513e6f4f6bb67bae47f60361c97cd33558bf1f0f405da0ae447f0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}